{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f5870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\jay\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "from PyPDF2 import PdfReader\n",
    "from pathlib import Path\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fce83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f8f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resume(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        pdf_reader = PdfReader(file)\n",
    "        resume_text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            resume_text += page.extract_text()\n",
    "    candidate_name = extract_candidate_name(resume_text) \n",
    "    return nlp(resume_text), candidate_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a55fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_name(resume_text):\n",
    "    candidate_name = \"\"\n",
    "    for token in resume_text.split():\n",
    "        if token.istitle():\n",
    "            candidate_name += token + \" \"\n",
    "        elif candidate_name:\n",
    "            break\n",
    "    return candidate_name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288e3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description():\n",
    "    job_description = input(\"Enter job description: \")\n",
    "    return nlp(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b11463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate(resume, job_description, years_of_experience, location_preference):\n",
    "    ##the metrics can be adjusted as needed\n",
    "    score = 0\n",
    "    similarity = resume.similarity(job_description)\n",
    "    score += similarity\n",
    "    \n",
    "    years_exp = extract_years_of_experience(resume)\n",
    "    location = extract_location(resume)\n",
    "    \n",
    "    if years_exp >= years_of_experience and location == location_preference:\n",
    "        score += 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97e5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years_of_experience(resume):\n",
    "    years_exp = 0\n",
    "    for ent in resume.ents:\n",
    "        if ent.label_ == \"DATE\" and \"year\" in ent.text.lower():\n",
    "            for token in ent:\n",
    "                if token.pos_ == \"NUM\":\n",
    "                    years_exp = int(token.text)\n",
    "    return years_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde61a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(resume):\n",
    "    location = \"\"\n",
    "    for ent in resume.ents:\n",
    "        if ent.label_ == \"GPE\":\n",
    "            location = ent.text\n",
    "            break\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0c4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_candidates(resumes, job_description, years_of_experience, location_preference, top_n=20):\n",
    "    scores = defaultdict(int)\n",
    "    for resume_path in resumes:\n",
    "        resume, candidate_name = parse_resume(resume_path)\n",
    "        score = evaluate_candidate(resume, job_description, years_of_experience, location_preference)\n",
    "        scores[candidate_name] = (resume_path, score)\n",
    "    top_candidates = nlargest(top_n, scores.items(), key=lambda x: x[1][1])\n",
    "    return top_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc66861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f77919eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of resumes: 3\n",
      "Enter path to resume 1 (PDF): r1.pdf\n",
      "Enter path to resume 2 (PDF): r2.pdf\n",
      "Enter path to resume 3 (PDF): r3.pdf\n",
      "Enter job description: Token Metrics is seeking a multi-talented Big Data Engineer intern to facilitate the operations of our Data Scientists and Engineering team. The Big Data Engineer intern will be responsible to employ various tools and techniques to construct frameworks that prepare information using SQL, Python, R, Java, and C++. The Big Data Engineer intern will be responsible for employing machine learning techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field. During various aspects of this process, you should collaborate with coworkers to ensure that your approach meets the needs of each project.   The duration of the Token Metrics internship program is 3 months. It is an evaluative unpaid internship with the possibility of return offers, depending on the company's needs.   Responsibilities   Compile and analyze data, processes, and codes to troubleshoot problems and identify areas for improvement Collaborating with the front-end developers and other team members to establish objectives and design more functional, cohesive codes to enhance the user experience Developing ideas for new programs, products, or features by monitoring industry developments and trends Recording data and reporting it to proper parties, such as clients or leadership Participating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team members Taking lead on projects, as needed  Requirements   Bachelorâ€™s degree in computer programming, computer science, or a related field More education or experience may be required Fluency or understanding of specific languages, such as Java, PHP, or Python, and operating systems may be required Strong understanding of the web development cycle and programming techniques and tools Focus on efficiency, user experience, and process improvement Excellent project and time management skills Strong problem solving and verbal and written communication skills Ability to work independently or with a group  About Token Metrics   Token Metrics helps crypto investors build profitable portfolios using artificial intelligence-based crypto indices, rankings, and price predictions.   Token Metrics has a diverse set of customers, from retail investors and traders to crypto fund managers, in more than 50 countries.\n",
      "Enter years of experience required: 1\n",
      "Enter location preference: Vizianagaram\n",
      "Top candidates:\n",
      "Rank: 1, Name: Django, Resume Path: r3.pdf, Score: 0.6306313631216467\n",
      "Rank: 2, Name: Bandi Jaya Sai Srikar Visakhapatnam, Andhra Pradesh, India, Resume Path: r1.pdf, Score: 0.5288706790431127\n",
      "Rank: 3, Name: Enthusiastic, Resume Path: r2.pdf, Score: 0.4798111147841933\n"
     ]
    }
   ],
   "source": [
    "num_resumes = int(input(\"Enter the number of resumes: \"))\n",
    "resumes = []\n",
    "for i in range(num_resumes):\n",
    "    resume_path = input(f\"Enter path to resume {i+1} (PDF): \")\n",
    "    resumes.append(resume_path)\n",
    "\n",
    "job_description = get_job_description()\n",
    "years_of_experience = int(input(\"Enter years of experience required: \"))\n",
    "location_preference = input(\"Enter location preference: \")\n",
    "\n",
    "top_candidates = find_top_candidates(resumes, job_description, years_of_experience, location_preference)\n",
    "print(\"Top candidates:\")\n",
    "for rank, (name, (resume_path, score)) in enumerate(top_candidates, start=1):\n",
    "    print(f\"Rank: {rank}, Name: {name}, Resume Path: {resume_path}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe470c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jay",
   "language": "python",
   "name": "jay"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
